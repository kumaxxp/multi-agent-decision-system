"""
è­°è«–çµæœåˆ†æãƒ»è¡¨ç¤ºãƒ„ãƒ¼ãƒ«
JSONãƒ­ã‚°ã‚’åˆ†æã—ã¦è¦‹ã‚„ã™ã„å½¢å¼ã§è¡¨ç¤º
"""

import json
import os
from datetime import datetime
from typing import Dict, List, Any, Optional
import argparse
from pathlib import Path


class ResultAnalyzer:
    """çµæœåˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.log_dir = "intelligent_collaboration_logs"
        
    def list_available_sessions(self) -> List[Dict[str, str]]:
        """åˆ©ç”¨å¯èƒ½ãªã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸€è¦§ã‚’å–å¾—"""
        if not os.path.exists(self.log_dir):
            return []
        
        sessions = []
        for file_name in os.listdir(self.log_dir):
            if file_name.endswith('.json') and file_name.startswith('intelligent_session_'):
                session_id = file_name.replace('intelligent_session_', '').replace('.json', '')
                file_path = os.path.join(self.log_dir, file_name)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’å–å¾—
                stat = os.stat(file_path)
                created_time = datetime.fromtimestamp(stat.st_ctime).strftime('%Y-%m-%d %H:%M')
                file_size = f"{stat.st_size / 1024:.1f} KB"
                
                sessions.append({
                    "session_id": session_id,
                    "file_name": file_name,
                    "created_time": created_time,
                    "file_size": file_size
                })
        
        return sorted(sessions, key=lambda x: x['session_id'], reverse=True)
    
    def load_session(self, session_id: str) -> Optional[Dict[str, Any]]:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³çµæœã‚’èª­ã¿è¾¼ã¿"""
        file_path = os.path.join(self.log_dir, f"intelligent_session_{session_id}.json")
        
        if not os.path.exists(file_path):
            return None
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âŒ ã‚»ãƒƒã‚·ãƒ§ãƒ³èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def analyze_session(self, session_data: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³çµæœã‚’åˆ†æ"""
        
        session_info = session_data["session_info"]
        agents = session_data["agents"]
        discussion_rounds = session_data["discussion_rounds"]
        final_conclusion = session_data["final_conclusion"]
        metrics = session_data["overall_collaboration_metrics"]
        
        # åŸºæœ¬çµ±è¨ˆ
        basic_stats = {
            "topic": session_info["topic"],
            "duration_rounds": session_info["actual_rounds"],
            "total_agents": len(agents),
            "total_opinions": metrics["total_opinions"],
            "consensus_achieved": final_conclusion["consensus_level"] >= 0.7
        }
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ†æ
        agent_analysis = self._analyze_agents(agents, discussion_rounds)
        
        # ãƒ©ã‚¦ãƒ³ãƒ‰åˆ¥åˆ†æ
        round_analysis = self._analyze_rounds(discussion_rounds)
        
        # å”èª¿ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        collaboration_patterns = self._analyze_collaboration_patterns(discussion_rounds)
        
        # æ„è¦‹é€²åŒ–åˆ†æ
        opinion_evolution = self._analyze_opinion_evolution(discussion_rounds)
        
        return {
            "basic_stats": basic_stats,
            "agent_analysis": agent_analysis,
            "round_analysis": round_analysis,
            "collaboration_patterns": collaboration_patterns,
            "opinion_evolution": opinion_evolution,
            "final_conclusion": final_conclusion,
            "metrics": metrics
        }
    
    def _analyze_agents(self, agents: List[Dict[str, Any]], discussion_rounds: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ†æ"""
        
        agent_stats = {}
        
        for agent in agents:
            name = agent["name"]
            expertise = agent["expertise_area"]
            
            # å„ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã®ç™ºè¨€ã‚’åˆ†æ
            responses = []
            opinion_types = []
            confidences = []
            
            for round_data in discussion_rounds:
                for response in round_data["agent_responses"]:
                    if response["agent_name"] == name:
                        responses.append(response)
                        opinion_types.append(response["opinion"]["type"])
                        confidences.append(response["opinion"]["confidence"])
            
            # çµ±è¨ˆè¨ˆç®—
            avg_confidence = sum(confidences) / len(confidences) if confidences else 0
            most_common_opinion = max(set(opinion_types), key=opinion_types.count) if opinion_types else "neutral"
            
            agent_stats[name] = {
                "expertise_area": expertise,
                "personality": agent["personality"],
                "total_responses": len(responses),
                "average_confidence": round(avg_confidence, 2),
                "dominant_opinion_type": most_common_opinion,
                "opinion_consistency": self._calculate_opinion_consistency(opinion_types),
                "influence_score": self._calculate_influence_score(responses)
            }
        
        return agent_stats
    
    def _analyze_rounds(self, discussion_rounds: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ãƒ©ã‚¦ãƒ³ãƒ‰åˆ¥åˆ†æ"""
        
        round_analysis = []
        
        for round_data in discussion_rounds:
            round_num = round_data["round_number"]
            responses = round_data["agent_responses"]
            
            # æ„è¦‹åˆ†å¸ƒ
            opinion_distribution = {}
            confidence_scores = []
            evidence_usage = 0
            
            for response in responses:
                opinion_type = response["opinion"]["type"]
                confidence = response["opinion"]["confidence"]
                evidence = response["opinion"]["evidence"]
                
                opinion_distribution[opinion_type] = opinion_distribution.get(opinion_type, 0) + 1
                confidence_scores.append(confidence)
                
                if evidence:
                    evidence_usage += 1
            
            # å”èª¿åˆ†æãŒã‚ã‚Œã°ãã‚Œã‚‚å«ã‚ã‚‹
            collaboration_info = {}
            if "collaboration_analysis" in round_data:
                collab = round_data["collaboration_analysis"]
                collaboration_info = {
                    "conflict_level": collab["conflict_level"],
                    "consensus_level": collab["consensus"]["consensus_level"],
                    "agreed_points": len(collab["consensus"]["agreed_points"]),
                    "disagreed_points": len(collab["consensus"]["disagreed_points"])
                }
            
            round_analysis.append({
                "round_number": round_num,
                "opinion_distribution": opinion_distribution,
                "average_confidence": round(sum(confidence_scores) / len(confidence_scores), 2) if confidence_scores else 0,
                "evidence_usage_rate": round(evidence_usage / len(responses), 2) if responses else 0,
                "collaboration_metrics": collaboration_info,
                "key_themes": self._extract_key_themes(responses)
            })
        
        return round_analysis
    
    def _analyze_collaboration_patterns(self, discussion_rounds: List[Dict[str, Any]]) -> Dict[str, Any]:
        """å”èª¿ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        
        conflict_levels = []
        consensus_levels = []
        
        for round_data in discussion_rounds:
            if "collaboration_analysis" in round_data:
                collab = round_data["collaboration_analysis"]
                conflict_levels.append(collab["conflict_level"])
                consensus_levels.append(collab["consensus"]["consensus_level"])
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è­˜åˆ¥
        if len(consensus_levels) >= 2:
            consensus_trend = "increasing" if consensus_levels[-1] > consensus_levels[0] else ("decreasing" if consensus_levels[-1] < consensus_levels[0] else "stable")
        else:
            consensus_trend = "insufficient_data"
        
        return {
            "conflict_progression": conflict_levels,
            "consensus_progression": consensus_levels,
            "consensus_trend": consensus_trend,
            "peak_conflict": max(conflict_levels) if conflict_levels else "none",
            "final_consensus": consensus_levels[-1] if consensus_levels else 0,
            "collaboration_effectiveness": self._assess_collaboration_effectiveness(conflict_levels, consensus_levels)
        }
    
    def _analyze_opinion_evolution(self, discussion_rounds: List[Dict[str, Any]]) -> Dict[str, Any]:
        """æ„è¦‹é€²åŒ–åˆ†æ"""
        
        agent_opinion_evolution = {}
        
        for round_data in discussion_rounds:
            round_num = round_data["round_number"]
            
            for response in round_data["agent_responses"]:
                agent_name = response["agent_name"]
                opinion_type = response["opinion"]["type"]
                confidence = response["opinion"]["confidence"]
                
                if agent_name not in agent_opinion_evolution:
                    agent_opinion_evolution[agent_name] = []
                
                agent_opinion_evolution[agent_name].append({
                    "round": round_num,
                    "opinion": opinion_type,
                    "confidence": confidence
                })
        
        # é€²åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ
        evolution_patterns = {}
        for agent_name, evolution in agent_opinion_evolution.items():
            if len(evolution) >= 2:
                initial_opinion = evolution[0]["opinion"]
                final_opinion = evolution[-1]["opinion"]
                
                if initial_opinion == final_opinion:
                    pattern = "consistent"
                elif self._opinion_distance(initial_opinion, final_opinion) <= 1:
                    pattern = "slight_shift"
                else:
                    pattern = "major_shift"
                
                evolution_patterns[agent_name] = {
                    "pattern": pattern,
                    "initial_opinion": initial_opinion,
                    "final_opinion": final_opinion,
                    "confidence_change": evolution[-1]["confidence"] - evolution[0]["confidence"]
                }
        
        return {
            "agent_evolutions": agent_opinion_evolution,
            "evolution_patterns": evolution_patterns,
            "stability_score": self._calculate_stability_score(evolution_patterns)
        }
    
    def _calculate_opinion_consistency(self, opinion_types: List[str]) -> float:
        """æ„è¦‹ä¸€è²«æ€§ã‚’è¨ˆç®—"""
        if not opinion_types:
            return 0.0
        
        most_common = max(set(opinion_types), key=opinion_types.count)
        consistency = opinion_types.count(most_common) / len(opinion_types)
        return round(consistency, 2)
    
    def _calculate_influence_score(self, responses: List[Dict[str, Any]]) -> float:
        """å½±éŸ¿åŠ›ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        # ç™ºè¨€æ•°ã€ä¿¡é ¼åº¦ã€è¨¼æ‹ ä½¿ç”¨é »åº¦ã‚’åŸºã«è¨ˆç®—
        if not responses:
            return 0.0
        
        total_confidence = sum(r["opinion"]["confidence"] for r in responses)
        evidence_count = sum(1 for r in responses if r["opinion"]["evidence"])
        
        influence = (total_confidence + evidence_count) / len(responses)
        return round(min(influence, 1.0), 2)
    
    def _extract_key_themes(self, responses: List[Dict[str, Any]]) -> List[str]:
        """ä¸»è¦ãƒ†ãƒ¼ãƒã‚’æŠ½å‡ºï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é »åº¦åˆ†æï¼ˆå®Ÿéš›ã¯ã‚ˆã‚Šé«˜åº¦ãªNLPå‡¦ç†ãŒå¿…è¦ï¼‰
        all_text = " ".join([r["response"] for r in responses])
        
        # ã‚ˆãå‡ºç¾ã™ã‚‹å˜èªã‚’æŠ½å‡ºï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
        words = all_text.split()
        word_counts = {}
        
        for word in words:
            if len(word) > 3:  # çŸ­ã„å˜èªã‚’é™¤å¤–
                word_counts[word] = word_counts.get(word, 0) + 1
        
        # é »å‡ºå˜èªä¸Šä½3ã¤ã‚’è¿”ã™
        sorted_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)
        return [word for word, count in sorted_words[:3] if count >= 2]
    
    def _assess_collaboration_effectiveness(self, conflict_levels: List[str], consensus_levels: List[float]) -> str:
        """å”èª¿åŠ¹æœã‚’è©•ä¾¡"""
        if not conflict_levels or not consensus_levels:
            return "insufficient_data"
        
        final_consensus = consensus_levels[-1]
        
        if final_consensus >= 0.8:
            return "highly_effective"
        elif final_consensus >= 0.6:
            return "moderately_effective"
        elif final_consensus >= 0.4:
            return "partially_effective"
        else:
            return "low_effectiveness"
    
    def _opinion_distance(self, opinion1: str, opinion2: str) -> int:
        """æ„è¦‹é–“ã®è·é›¢ã‚’è¨ˆç®—"""
        opinion_scale = {
            "strongly_disagree": 0,
            "disagree": 1,
            "neutral": 2,
            "agree": 3,
            "strongly_agree": 4
        }
        
        return abs(opinion_scale.get(opinion1, 2) - opinion_scale.get(opinion2, 2))
    
    def _calculate_stability_score(self, evolution_patterns: Dict[str, Dict[str, Any]]) -> float:
        """å®‰å®šæ€§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        if not evolution_patterns:
            return 0.0
        
        consistent_agents = sum(1 for pattern in evolution_patterns.values() if pattern["pattern"] == "consistent")
        stability = consistent_agents / len(evolution_patterns)
        return round(stability, 2)
    
    def display_analysis(self, analysis: Dict[str, Any]):
        """åˆ†æçµæœã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«è¡¨ç¤º"""
        print("\nğŸ” === è­°è«–åˆ†æãƒ¬ãƒãƒ¼ãƒˆ ===\n")
        
        # åŸºæœ¬çµ±è¨ˆ
        stats = analysis["basic_stats"]
        print("ğŸ“Š åŸºæœ¬çµ±è¨ˆ:")
        print(f"  è­°è«–ãƒˆãƒ”ãƒƒã‚¯: {stats['topic']}")
        print(f"  å®Ÿæ–½ãƒ©ã‚¦ãƒ³ãƒ‰: {stats['duration_rounds']}")
        print(f"  å‚åŠ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: {stats['total_agents']}äºº")
        print(f"  ç·ç™ºè¨€æ•°: {stats['total_opinions']}")
        print(f"  åˆæ„é”æˆ: {'âœ…' if stats['consensus_achieved'] else 'âŒ'}")
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ†æ
        print(f"\nğŸ‘¥ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ†æ:")
        agent_analysis = analysis["agent_analysis"]
        for name, data in agent_analysis.items():
            print(f"  {name} ({data['expertise_area']}):")
            print(f"    å¹³å‡ä¿¡é ¼åº¦: {data['average_confidence']:.2f}")
            print(f"    ä¸»è¦æ„è¦‹: {data['dominant_opinion_type']}")
            print(f"    ä¸€è²«æ€§: {data['opinion_consistency']:.2f}")
            print(f"    å½±éŸ¿åŠ›: {data['influence_score']:.2f}")
        
        # ãƒ©ã‚¦ãƒ³ãƒ‰é€²å±•
        print(f"\nğŸ”„ ãƒ©ã‚¦ãƒ³ãƒ‰åˆ¥é€²å±•:")
        for round_data in analysis["round_analysis"]:
            round_num = round_data["round_number"]
            print(f"  ãƒ©ã‚¦ãƒ³ãƒ‰{round_num}:")
            print(f"    å¹³å‡ä¿¡é ¼åº¦: {round_data['average_confidence']:.2f}")
            print(f"    è¨¼æ‹ ä½¿ç”¨ç‡: {round_data['evidence_usage_rate']:.2f}")
            
            if round_data["collaboration_metrics"]:
                collab = round_data["collaboration_metrics"]
                print(f"    å¯¾ç«‹ãƒ¬ãƒ™ãƒ«: {collab['conflict_level']}")
                print(f"    åˆæ„åº¦: {collab['consensus_level']:.2f}")
        
        # å”èª¿ãƒ‘ã‚¿ãƒ¼ãƒ³
        print(f"\nğŸ¤ å”èª¿ãƒ‘ã‚¿ãƒ¼ãƒ³:")
        collab_patterns = analysis["collaboration_patterns"]
        print(f"  åˆæ„ã®å‚¾å‘: {collab_patterns['consensus_trend']}")
        print(f"  æœ€çµ‚åˆæ„åº¦: {collab_patterns['final_consensus']:.2f}")
        print(f"  å”èª¿åŠ¹æœ: {collab_patterns['collaboration_effectiveness']}")
        
        # æœ€çµ‚çµè«–
        print(f"\nğŸ¯ æœ€çµ‚çµè«–:")
        conclusion = analysis["final_conclusion"]
        print(f"  {conclusion['conclusion_text']}")
        print(f"  æ¨å¥¨äº‹é …: {conclusion['recommendation']}")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    parser = argparse.ArgumentParser(description="è­°è«–çµæœåˆ†æãƒ„ãƒ¼ãƒ«")
    parser.add_argument("--list", action="store_true", help="åˆ©ç”¨å¯èƒ½ãªã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸€è¦§ã‚’è¡¨ç¤º")
    parser.add_argument("--session", type=str, help="åˆ†æã™ã‚‹ã‚»ãƒƒã‚·ãƒ§ãƒ³ID")
    parser.add_argument("--html", action="store_true", help="HTMLå½¢å¼ã§å‡ºåŠ›")
    
    args = parser.parse_args()
    
    analyzer = ResultAnalyzer()
    
    if args.list:
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸€è¦§è¡¨ç¤º
        sessions = analyzer.list_available_sessions()
        if not sessions:
            print("ğŸ“‚ ä¿å­˜ã•ã‚ŒãŸã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        print("ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªã‚»ãƒƒã‚·ãƒ§ãƒ³:\n")
        for session in sessions:
            print(f"  {session['session_id']}")
            print(f"    ä½œæˆæ—¥æ™‚: {session['created_time']}")
            print(f"    ã‚µã‚¤ã‚º: {session['file_size']}")
            print()
        
        return
    
    if args.session:
        # ç‰¹å®šã‚»ãƒƒã‚·ãƒ§ãƒ³ã®åˆ†æ
        session_data = analyzer.load_session(args.session)
        if not session_data:
            print(f"âŒ ã‚»ãƒƒã‚·ãƒ§ãƒ³ {args.session} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        analysis = analyzer.analyze_session(session_data)
        
        if args.html:
            # HTMLå‡ºåŠ›ï¼ˆå¾Œã§å®Ÿè£…ï¼‰
            print("ğŸ“„ HTMLå‡ºåŠ›ã¯æº–å‚™ä¸­ã§ã™ã€‚")
        else:
            # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›
            analyzer.display_analysis(analysis)
        
        return
    
    # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰
    sessions = analyzer.list_available_sessions()
    if not sessions:
        print("ğŸ“‚ ä¿å­˜ã•ã‚ŒãŸã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        print("ã¾ãš main_intelligent_collaboration.py ã‚’å®Ÿè¡Œã—ã¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
        return
    
    print("ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªã‚»ãƒƒã‚·ãƒ§ãƒ³:")
    for i, session in enumerate(sessions, 1):
        print(f"  {i}. {session['session_id']} ({session['created_time']})")
    
    try:
        choice = int(input("\nåˆ†æã—ãŸã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ç•ªå·ã‚’é¸æŠã—ã¦ãã ã•ã„: ")) - 1
        if 0 <= choice < len(sessions):
            session_id = sessions[choice]["session_id"]
            session_data = analyzer.load_session(session_id)
            
            if session_data:
                analysis = analyzer.analyze_session(session_data)
                analyzer.display_analysis(analysis)
            else:
                print("âŒ ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        else:
            print("âŒ ç„¡åŠ¹ãªé¸æŠã§ã™ã€‚")
            
    except ValueError:
        print("âŒ ç„¡åŠ¹ãªå…¥åŠ›ã§ã™ã€‚")


if __name__ == "__main__":
    main()